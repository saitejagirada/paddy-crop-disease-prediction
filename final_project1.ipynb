{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v_6hAv1qgEjk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMoAJ0YW7jm_",
    "outputId": "1cf5eaa6-34c9-4158-86dc-4654803ac2fd"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F08Yb1kX8w5i",
    "outputId": "8dc8eafb-9829-4c2a-85be-3b9f5b31744c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train:\n",
      "leaf_blast\n",
      "Rice Hispa\n",
      "Neck_Blast\n",
      ".DS_Store\n",
      "Sheath Blight\n",
      "healthy\n",
      "bacterial_leaf_blight\n",
      "brown_spot\n",
      "leaf_scald\n",
      "Tungro\n",
      "narrow_brown_spot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List the contents of a specific folder in your Drive, for example, a 'datasets' folder\n",
    "drive_path = \"train\"\n",
    "\n",
    "if os.path.exists(drive_path):\n",
    "    files = os.listdir(drive_path)\n",
    "    print(f\"Files in {drive_path}:\")\n",
    "    for file in files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(f\"The directory {drive_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8p2qfwSFgf4u",
    "outputId": "6bbc58f0-15f6-40f1-e35f-343fe7ddd7ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giradasaiteja/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/giradasaiteja/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model=models.resnet34(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "\n",
    "# Freeze all layers except the final classification layer\n",
    "#for name, param in model.named_parameters():\n",
    "#    if 'fc' in name: # Check if the parameter belongs to the final fully connected layer\n",
    "#        param.requires_grad = True\n",
    "#    else:\n",
    "#        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "95eaae4e"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define transformations for training data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define transformations for testing data\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWvxSqCM7arU",
    "outputId": "c48935ad-5c4e-429c-a1b2-73e7de40b86e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in the dataset: 1089\n",
      "Splitting into 871 training samples and 218 validation samples.\n",
      "DataLoaders for training and validation have been created successfully.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "\n",
    "# Assume train_transforms is already defined\n",
    "\n",
    "# 1. Define the path to your data directory\n",
    "train_dir = 'train' # Corrected path\n",
    "\n",
    "# 2. Create the full ImageFolder dataset\n",
    "full_dataset = ImageFolder(root=train_dir, transform=train_transforms)\n",
    "print(f\"Total images in the dataset: {len(full_dataset)}\")\n",
    "\n",
    "# 3. Define the sizes for your training and validation sets\n",
    "# Let's use an 80/20 split of the entire dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "print(f\"Splitting into {train_size} training samples and {val_size} validation samples.\")\n",
    "\n",
    "\n",
    "# 4. Perform the split using random_split\n",
    "# This ensures the validation set has not been seen during training\n",
    "# A generator is used for reproducibility of the split\n",
    "generator = torch.Generator().manual_seed(42) # Use a fixed seed for consistent splits\n",
    "train_subset, val_subset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "# 5. Create the DataLoaders from the new Subset objects\n",
    "# Use clear and distinct variable names\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2, # Reduced number of workers\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,  # No need to shuffle the validation set\n",
    "    num_workers=2, # Reduced number of workers\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"DataLoaders for training and validation have been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q60Ft3Jt7arU"
   },
   "outputs": [],
   "source": [
    "criterian=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "d55881f0"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "540b2f05"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model,train_loader,loss_fn,optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss=0.0\n",
    "    correc_predict=0\n",
    "    total_samp=0\n",
    "    for inputs,labels in train_loader:\n",
    "        inputs,labels=inputs.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(inputs)\n",
    "        loss=loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # Use xm.optimizer_step for TPU # Add mark_step for TPU\n",
    "\n",
    "\n",
    "        running_loss=loss.item()*inputs.size(0)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total_samp+=labels.size(0)\n",
    "        correc_predict+=(predicted==labels).sum().item()\n",
    "    epoch_loss=running_loss/total_samp\n",
    "    epoch_acc=100*correc_predict/total_samp\n",
    "\n",
    "    return epoch_loss,epoch_acc\n",
    "\n",
    "def evaluate(model,val_loader,loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss=0.0\n",
    "    correc_predict=0\n",
    "    total_samp=0\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in val_loader:\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "\n",
    "            outputs=model(inputs)\n",
    "            loss=loss_fn(outputs,labels)\n",
    "\n",
    "            running_loss=loss.item()*inputs.size(0)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total_samp+=labels.size(0)\n",
    "        correc_predict+=(predicted==labels).sum().item()\n",
    "    epoch_loss=running_loss/total_samp\n",
    "    epoch_acc=100*correc_predict/total_samp\n",
    "\n",
    "    return epoch_loss,epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "992e619b"
   },
   "source": [
    "**Reasoning**:\n",
    "I will execute the training loop for a specified number of epochs and evaluate the model periodically. Since the previous steps for setting up the training loop and evaluation are complete, I can combine these into a single block to train and evaluate the model for a few epochs. I will set the number of epochs to 5 and evaluate after each epoch to monitor the training progress.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da8e2df6",
    "outputId": "295f2ef6-defa-4186-f966-e6ac9f1e78bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1:train_loss:0.00,train_acc88.7486:eval_loss:0.63,eval_acc92.3077:\n",
      "epoch2:train_loss:0.00,train_acc92.9966:eval_loss:0.47,eval_acc88.4615:\n",
      "epoch3:train_loss:0.00,train_acc92.7669:eval_loss:0.56,eval_acc88.4615:\n",
      "epoch4:train_loss:0.01,train_acc93.5706:eval_loss:0.24,eval_acc92.3077:\n",
      "epoch5:train_loss:0.00,train_acc94.2595:eval_loss:0.25,eval_acc88.4615:\n",
      "epoch6:train_loss:0.00,train_acc92.9966:eval_loss:0.33,eval_acc92.3077:\n",
      "epoch7:train_loss:0.00,train_acc94.8335:eval_loss:0.39,eval_acc88.4615:\n",
      "epoch8:train_loss:0.01,train_acc94.3743:eval_loss:0.27,eval_acc92.3077:\n",
      "epoch9:train_loss:0.01,train_acc94.0299:eval_loss:0.34,eval_acc88.4615:\n",
      "epoch10:train_loss:0.01,train_acc94.7187:eval_loss:0.51,eval_acc92.3077:\n",
      "epoch11:train_loss:0.01,train_acc93.4558:eval_loss:0.42,eval_acc88.4615:\n",
      "epoch12:train_loss:0.01,train_acc93.5706:eval_loss:0.44,eval_acc88.4615:\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "eproaches=12\n",
    "model.to(device)\n",
    "for epoch in range(eproaches):\n",
    "    train_loss,train_acc=train(model,train_loader,loss_fn,optimizer)\n",
    "    eval_loss,eval_acc=evaluate(model,val_loader,loss_fn)\n",
    "\n",
    "    print(f\"epoch{epoch+1}:\"\n",
    "          f\"train_loss:{train_loss:.2f},train_acc{train_acc:.4f}:\"\n",
    "          f\"eval_loss:{eval_loss:.2f},eval_acc{eval_acc:.4f}:\")\n",
    "print(\"training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to rice_leaf_disease.pth\n"
     ]
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = 'rice_leaf_disease.pth'\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up your custom model and environment...\n",
      "Using device: mps\n",
      "predict_custom.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=device), strict=False)\n",
      "Setup complete. Starting prediction...\n",
      "------------------------------\n",
      "Image Path:   rice_hispa1.jpg\n",
      "Prediction:   Rice Hispa\n",
      "Confidence:   96.11%\n"
     ]
    }
   ],
   "source": [
    "! python3 predict_custom.py rice_hispa1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
